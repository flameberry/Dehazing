{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bIFc8-utB1LS",
    "outputId": "d6a11bef-9f52-49bc-ad59-d7481c783463"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-22 07:37:16--  https://vedas.sac.gov.in/static/pdf/SIH_2022/SS594_Multispectral_Dehazing.zip\n",
      "Resolving vedas.sac.gov.in (vedas.sac.gov.in)... 103.99.192.69, 2001:df0:4840::69\n",
      "Connecting to vedas.sac.gov.in (vedas.sac.gov.in)|103.99.192.69|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1481111113 (1.4G) [application/x-zip-compressed]\n",
      "Saving to: ‘SS594_Multispectral_Dehazing.zip.1’\n",
      "\n",
      ".zip.1                3%[                    ]  44.41M  3.35MB/s    eta 10m 54s^C\n",
      "Archive:  SS594_Multispectral_Dehazing.zip\n",
      "replace SS594_Multispectral_Dehazing/GT/01_GT.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n",
      "mv: cannot stat 'SS594_Multispectral_Dehazing/Haze1k/Haze1k/Haze1k_thin/dataset/valid': No such file or directory\n",
      "mv: cannot stat 'SS594_Multispectral_Dehazing/Haze1k/Haze1k/Haze1k_thick/dataset/valid': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!wget https://vedas.sac.gov.in/static/pdf/SIH_2022/SS594_Multispectral_Dehazing.zip\n",
    "!unzip SS594_Multispectral_Dehazing.zip\n",
    "!mv SS594_Multispectral_Dehazing/Haze1k/Haze1k/Haze1k_thin/dataset/valid SS594_Multispectral_Dehazing/Haze1k/Haze1k/Haze1k_thin/dataset/val\n",
    "!mv SS594_Multispectral_Dehazing/Haze1k/Haze1k/Haze1k_thick/dataset/valid SS594_Multispectral_Dehazing/Haze1k/Haze1k/Haze1k_thick/dataset/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "k_1V0W4KBeJr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.10.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "k_1V0W4KBeJr"
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'child' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpexpect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Vanilla Pexpect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0mflush\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command, args, timeout, maxread, searchwindowsize, logfile, cwd, env, ignore_sighup, echo, preexec_fn, encoding, codec_errors, dimensions, use_poll)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreexec_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_poll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_poll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawn\u001b[0;34m(self, command, args, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    302\u001b[0m         self.ptyproc = self._spawnpty(self.args, env=self.env,\n\u001b[0;32m--> 303\u001b[0;31m                                      cwd=self.cwd, **kwargs)\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawnpty\u001b[0;34m(self, args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;34m'''Spawn a pty and return an instance of PtyProcess.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mptyprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPtyProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ptyprocess/ptyprocess.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(cls, argv, cwd, env, echo, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_err_pipe_write\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mexec_err_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_err_pipe_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_err_pipe_read\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8179552e98d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'install torchvision'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2324\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2325\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2326\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2327\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-106>\u001b[0m in \u001b[0;36mpip\u001b[0;34m(self, line)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/packaging.py\u001b[0m in \u001b[0;36mpip\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     66\u001b[0m           \u001b[0;34m%\u001b[0m\u001b[0mpip\u001b[0m \u001b[0minstall\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpkgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \"\"\"\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-m'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Note: you may need to restart the kernel to use updated packages.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;31m# Ensure new system_piped implementation is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;31m# (the character is known as ETX for 'End of Text', see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;31m# curses.ascii.ETX).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;31m# Read and print any more output the program might produce on its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;31m# way out.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'child' referenced before assignment"
     ]
    }
   ],
   "source": [
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "k_1V0W4KBeJr"
   },
   "outputs": [],
   "source": [
    "from PIL.Image import Image\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def Preprocess(image: Image) -> torch.Tensor:\n",
    "    # Contrast Enhancement\n",
    "    transform = transforms.Compose([\n",
    "        transforms.PILToTensor(),\n",
    "        transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05)\n",
    "        # transforms.functional.equalize\n",
    "    ])\n",
    "    transformedImage = transform(image)\n",
    "\n",
    "    # Gamma Correction\n",
    "    gammaCorrectedImage = transforms.functional.adjust_gamma(transformedImage, 2.2)\n",
    "\n",
    "    # Histogram Stretching\n",
    "    min_val = gammaCorrectedImage.min()\n",
    "    max_val = gammaCorrectedImage.max()\n",
    "    stretchedImage = (gammaCorrectedImage - min_val) / (max_val - min_val)\n",
    "    return stretchedImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yxntnn6tBm4F",
    "outputId": "3b3b241f-02a5-4499-a14a-d82f8cf9182c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.has_mps else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kzZDdZEjBq3j"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from enum import Enum\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class DatasetType(Enum):\n",
    "    Train = 0,\n",
    "    Test = 1,\n",
    "    Validation = 2\n",
    "\n",
    "    def ToString(self) -> str:\n",
    "        if self == DatasetType.Train:\n",
    "            return 'train'\n",
    "        elif self == DatasetType.Test:\n",
    "            return 'test'\n",
    "        elif self == DatasetType.Validation:\n",
    "            return 'val'\n",
    "\n",
    "class DehazingDataset(Dataset):\n",
    "    def __init__(self, dehazingDatasetPath: pathlib.Path, _type: DatasetType, transformFn=None, verbose: bool = False):\n",
    "        self.__DehazingDatasetPath = dehazingDatasetPath\n",
    "        self.__TransformFn = transformFn\n",
    "\n",
    "        self.__HazyImages = []\n",
    "        self.__ClearImages = []\n",
    "\n",
    "        for variant in ('Haze1k_thin', 'Haze1k_moderate', 'Haze1k_thick'):\n",
    "            inputPath = self.__DehazingDatasetPath / variant / 'dataset' / _type.ToString() / 'input'\n",
    "            targetPath = self.__DehazingDatasetPath / variant / 'dataset' / _type.ToString() / 'target'\n",
    "\n",
    "            self.__HazyImages += [inputPath / filename for filename in sorted(os.listdir(inputPath)) if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp'))]\n",
    "            self.__ClearImages += [targetPath / filename for filename in sorted(os.listdir(targetPath)) if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp'))]\n",
    "\n",
    "        # Filtering the mismatching (input, target) image pair\n",
    "        assert len(self.__HazyImages) == len(self.__ClearImages)\n",
    "        for hazyPath, clearPath in zip(self.__HazyImages, self.__ClearImages):\n",
    "            hazyImage = Image.open(hazyPath)\n",
    "            clearImage = Image.open(clearPath)\n",
    "            if hazyImage.size != clearImage.size:\n",
    "                self.__HazyImages.remove(hazyPath)\n",
    "                self.__ClearImages.remove(clearPath)\n",
    "            elif verbose:\n",
    "                print(hazyPath)\n",
    "                print(clearPath)\n",
    "\n",
    "        self.__Size = len(self.__HazyImages)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.__Size\n",
    "\n",
    "    def __getitem__(self, index) -> torch.Tensor:\n",
    "        hazyImage = None\n",
    "        clearImage = None\n",
    "        try:\n",
    "            hazyImage = torch.Tensor(self.__TransformFn(Image.open(self.__HazyImages[index]).convert('RGB')))\n",
    "            clearImage = torch.Tensor(self.__TransformFn(Image.open(self.__ClearImages[index]).convert('RGB')))\n",
    "        except OSError:\n",
    "            print(f'Error Loading: {self.__HazyImages[index]}')\n",
    "            print(f'Error Loading: {self.__ClearImages[index]}')\n",
    "\n",
    "            # Handle the case of empty images, e.g., skip the sample\n",
    "            # You can also replace the empty images with placeholder images if needed\n",
    "            # For now, let's just return a placeholder tensor\n",
    "            placeholder_image = torch.zeros((3, 512, 512), dtype=torch.float32)\n",
    "            return placeholder_image, placeholder_image\n",
    "\n",
    "        return hazyImage, clearImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68jCsl3VBvfz",
    "outputId": "28b1872e-1f5f-4b21-ce7e-1e946b7a3023"
   },
   "outputs": [],
   "source": [
    "datasetPath = pathlib.Path('SS594_Multispectral_Dehazing/Haze1k/Haze1k')\n",
    "trainingDataset = DehazingDataset(dehazingDatasetPath=datasetPath, _type=DatasetType.Train, transformFn=Preprocess, verbose=False)\n",
    "validationDataset = DehazingDataset(dehazingDatasetPath=datasetPath, _type=DatasetType.Validation, transformFn=Preprocess, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_jbFfVhBy60",
    "outputId": "3ffb1bb6-07e7-4d1a-b4d7-80a9f1f6e50f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960 105\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as tu_data\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "trainingDataLoader = tu_data.DataLoader(trainingDataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validationDataLoader = tu_data.DataLoader(validationDataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(len(trainingDataset), len(validationDataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Wz0QVa5TD4Pz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as tn_functional\n",
    "\n",
    "class AODnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AODnet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "        # Initialize the weights of the convolutional layer with a Gaussian distribution\n",
    "        nn.init.normal_(self.conv1.weight, mean=0.0, std=0.01)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=6, out_channels=3, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv4 = nn.Conv2d(in_channels=6, out_channels=3, kernel_size=7, stride=1, padding=3)\n",
    "        self.conv5 = nn.Conv2d(in_channels=12, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
    "        self.b = 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = tn_functional.relu(self.conv1(x))\n",
    "        x2 = tn_functional.relu(self.conv2(x1))\n",
    "        cat1 = torch.cat((x1, x2), 1)\n",
    "        x3 = tn_functional.relu(self.conv3(cat1))\n",
    "        cat2 = torch.cat((x2, x3), 1)\n",
    "        x4 = tn_functional.relu(self.conv4(cat2))\n",
    "        cat3 = torch.cat((x1, x2, x3, x4), 1)\n",
    "        k = tn_functional.relu(self.conv5(cat3))\n",
    "\n",
    "        if k.size() != x.size():\n",
    "            raise Exception(\"k, haze image are different size!\")\n",
    "\n",
    "        output = k * x - k + self.b\n",
    "        return tn_functional.relu(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QJY9GW7fEAyp",
    "outputId": "c6c819a4-a9e1-49e5-93d8-cfacb6b395e9"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-2\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 0.0001\n",
    "EPOCHS = 10\n",
    "GRADIENT_CLIP_VALUE = 0.5\n",
    "STEPS = len(trainingDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QJY9GW7fEAyp",
    "outputId": "c6c819a4-a9e1-49e5-93d8-cfacb6b395e9"
   },
   "outputs": [],
   "source": [
    "lre = torch.linspace(-2, -6, EPOCHS * STEPS)\n",
    "lrs = 10 ** lre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AODnet(\n",
      "  (conv1): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(6, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv4): Conv2d(6, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "  (conv5): Conv2d(12, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR, ReduceLROnPlateau\n",
    "\n",
    "model = AODnet().to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.MSELoss().to(device=device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# def lambdaLR(epoch):\n",
    "#     return lrs[epoch - 1]\n",
    "# scheduler = LambdaLR(optimizer, lr_lambda=lambdaLR)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=3, verbose=True, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kVi8u6MiEIxB",
    "outputId": "c07fdd93-95de-476a-8d52-2f5710ef7c7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.6/dist-packages (0.8.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from torchmetrics) (20.4)\n",
      "Requirement already satisfied: pyDeprecate==0.3.* in /usr/local/lib/python3.6/dist-packages (from torchmetrics) (0.3.2)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.6/dist-packages (from torchmetrics) (1.19.5)\n",
      "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.6/dist-packages (from torchmetrics) (1.10.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.1->torchmetrics) (4.1.1)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.1->torchmetrics) (0.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->torchmetrics) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->torchmetrics) (1.15.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jKO4bFW2EC3s",
    "outputId": "fc12ff24-1abf-4f2b-c8f0-41deef356702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training...\n",
      "Epoch: 1/10  |  Step: 1/15  |  lr: 0.010000  | Loss: 0.467733\n",
      "Epoch: 1/10  |  Step: 2/15  |  lr: 0.010000  | Loss: 0.284729\n",
      "Epoch: 1/10  |  Step: 3/15  |  lr: 0.010000  | Loss: 0.115446\n",
      "Epoch: 1/10  |  Step: 4/15  |  lr: 0.010000  | Loss: 0.054747\n",
      "Epoch: 1/10  |  Step: 5/15  |  lr: 0.010000  | Loss: 0.073421\n",
      "Error Loading: SS594_Multispectral_Dehazing/Haze1k/Haze1k/Haze1k_moderate/dataset/train/input/265.png\n",
      "Error Loading: SS594_Multispectral_Dehazing/Haze1k/Haze1k/Haze1k_moderate/dataset/train/target/265.png\n",
      "Epoch: 1/10  |  Step: 6/15  |  lr: 0.010000  | Loss: 0.084567\n",
      "Epoch: 1/10  |  Step: 7/15  |  lr: 0.010000  | Loss: 0.089532\n",
      "Epoch     8: reducing learning rate of group 0 to 8.0000e-03.\n",
      "Epoch: 1/10  |  Step: 8/15  |  lr: 0.008000  | Loss: 0.096852\n",
      "Epoch: 1/10  |  Step: 9/15  |  lr: 0.008000  | Loss: 0.105473\n",
      "Epoch: 1/10  |  Step: 10/15  |  lr: 0.008000  | Loss: 0.103228\n",
      "Epoch: 1/10  |  Step: 11/15  |  lr: 0.008000  | Loss: 0.097101\n",
      "Error Loading: SS594_Multispectral_Dehazing/Haze1k/Haze1k/Haze1k_moderate/dataset/train/input/271.png\n",
      "Error Loading: SS594_Multispectral_Dehazing/Haze1k/Haze1k/Haze1k_moderate/dataset/train/target/271.png\n",
      "Epoch    12: reducing learning rate of group 0 to 6.4000e-03.\n",
      "Epoch: 1/10  |  Step: 12/15  |  lr: 0.006400  | Loss: 0.096775\n",
      "Epoch: 1/10  |  Step: 13/15  |  lr: 0.006400  | Loss: 0.110874\n",
      "Epoch: 1/10  |  Step: 14/15  |  lr: 0.006400  | Loss: 0.099508\n",
      "Epoch: 1/10  |  Step: 15/15  |  lr: 0.006400  | Loss: 0.103005\n",
      "Epoch: 1/10 | Validation Model Saving Images\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "\n",
    "train_number = len(trainingDataLoader)\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "lre\n",
    "\n",
    "print(\"Started Training...\")\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    # -------------------------------------------------------------------\n",
    "    # start training\n",
    "    for step, (haze_image, ori_image) in enumerate(trainingDataLoader):\n",
    "        ori_image, haze_image = ori_image.to(device), haze_image.to(device)\n",
    "        # Forward Pass\n",
    "        dehaze_image = model(haze_image)\n",
    "        # Loss Calculation\n",
    "        loss = criterion(dehaze_image, ori_image)\n",
    "        # Setting the gradients to zero to avoid accumulation across steps\n",
    "        optimizer.zero_grad()\n",
    "        # Backward Propagation\n",
    "        loss.backward()\n",
    "        # Setting the clipping value of the gradients\n",
    "        torch.nn.utils.clip_grad_value_(model.parameters(), GRADIENT_CLIP_VALUE)\n",
    "        # Updating the gradients\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "\n",
    "        print(\n",
    "            \"Epoch: {}/{}  |  Step: {}/{}  |  lr: {:.6f}  | Loss: {:.6f}\".format(\n",
    "                epoch + 1, EPOCHS, step + 1, train_number, optimizer.param_groups[0][\"lr\"], loss.item()\n",
    "            )\n",
    "        )\n",
    "    # -------------------------------------------------------------------\n",
    "    # start validation\n",
    "    print(\"Epoch: {}/{} | Validation Model Saving Images\".format(epoch + 1, EPOCHS))\n",
    "    model.eval()\n",
    "    for step, (haze_image, ori_image) in enumerate(validationDataLoader):\n",
    "        if step > 10:  # only save image 10 times\n",
    "            break\n",
    "        ori_image, haze_image = ori_image.to(device), haze_image.to(device)\n",
    "        dehaze_image = model(haze_image)\n",
    "\n",
    "        # ssim = StructuralSimilarityIndexMeasure().to(device)\n",
    "        # ssim_val = ssim(dehaze_image, ori_image)\n",
    "        # ssim_fake_val = ssim(haze_image, ori_image)\n",
    "        # print(f\"SSIM: {ssim_val}, SSIM_Fake: {ssim_fake_val}\")\n",
    "        # perc = (ssim_val - ssim_fake_val) * 100.0 / (1.0 - ssim_fake_val)\n",
    "        # print(f\"Percentage Improvement: {perc} %\")\n",
    "\n",
    "        torchvision.utils.save_image(\n",
    "            torchvision.utils.make_grid(torch.cat((haze_image, dehaze_image, ori_image), 0), nrow=ori_image.shape[0]),\n",
    "            os.path.join(\"output\", \"{}_{}.jpg\".format(epoch + 1, step)),\n",
    "        )\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gswiG5jCEGsj"
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'saved_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3pT8eR2_O2LQ",
    "outputId": "44d786fd-dfcd-4519-b8b4-1ddfd522e30d"
   },
   "outputs": [],
   "source": [
    "!tar -zcvf output.tar.gz output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZM5g1rPEPO5F"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
